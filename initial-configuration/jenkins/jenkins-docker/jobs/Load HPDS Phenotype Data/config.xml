<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description>This job will load phenotype data from a variety of sources including both csv files and RDBMS queries.   &#xd;
&#xd;
This job starts by reading the a file located at &quot;/usr/local/docker-config/hpds_csv/phenotypeInputs.txt&quot;.  Each line of this text file should be the absolute path of a file containing wither csv formatted data (as described in the next section), or a SQL script to extract input data from an RDBMS source.  Any sql scripts MUST be named with a .sql extension (case insensitive).  &#xd;
If no phenotypeInputs.txt file is found, the loader will look for a single CSV file named &quot;/usr/local/docker-config/hpds_csv/allConcepts.csv&quot;.  When this job completes successfully, it will move any existing HPDS phenotype data to a direectory &quot;/usr/local/docker-config/hpds_bak&quot;, and the new data will be places in &quot;/usr/local/docker-config/hpds/&quot;.  &#xd;
&#xd;
The &quot;Start PIC-SURE&quot; job needs to be run after this job completes to refresh the HPDS data volume mount and allow access to the new data from the PIC-SURE interface.&#xd;
&#xd;
&#xd;
&#xd;
&#xd;
The expected CSV format for the data files is as follows:&#xd;
&#xd;
One header line, exactly matching this string:&#xd;
&#xd;
&quot;PATIENT_NUM&quot;,&quot;CONCEPT_PATH&quot;,&quot;NVAL_NUM&quot;,&quot;TVAL_CHAR&quot;,&quot;TIMESTAMP&quot;&#xd;
&#xd;
&#xd;
&#xd;
Each subsequent row in the data file (or SQL query output) must contain the following entries to match the header columns.  Please note, sorting the input data by the following column sequence will greatly speed up loading: CONCEPT_PATH,PATIENT_NUM,TIMESTAMP.&#xd;
&#xd;
PATIENT_NUM: This is an integer value identifying the subject of the recorded observation fact.&#xd;
&#xd;
CONCEPT_PATH: This is an identifier for the concept of the observation fact. For compatibility with the PIC-SURE UI this path should represent a location in a hierarchy where each level is separated by a backslash and with a leading and trailing backslash, e.g., &quot;\demographics\AGE\&quot;. In general this can be any string value, so the UI will display whatever is inside HPDS. If this HPDS instance is part of a PIC-SURE networked environment the same concept paths should be used in all sites involved in the network so that queries can be federated across the network.&#xd;
&#xd;
NVAL_NUM: A numeric value if this is a numeric concept, otherwise blank.&#xd;
&#xd;
TVAL_CHAR: A text value if this is a categorical concept, otherwise blank.&#xd;
&#xd;
TIMESTAMP: A timestamp for the observation fact, this should be expressed as the number of milliseconds since January 1, 1970 GMT. &#xd;
This is equivalent to the Unix Epoch time value for the time of the observation multiplied by 1000.&#xd;
</description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>
export PROFILING_OPTS=&quot;-Dcom.sun.management.jmxremote.port=9000 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=localhost&quot;

docker stop hpds-etl &amp;&amp; docker rm hpds-etl

rm -rf /usr/local/docker-config/hpds_temp
rm -rf /usr/local/docker-config/hpds_bak
mkdir -p /usr/local/docker-config/hpds_temp

#generate a new encryption key
openssl enc -aes-128-cbc -k secret -P | grep key | cut -d &apos;=&apos; -f2 &gt;  /usr/local/docker-config/hpds_temp/encryption_key

docker run --name=hpds-etl \
-v /usr/local/docker-config/hpds_temp:/opt/local/hpds \
-v /usr/local/docker-config/hpds_csv/allConcepts.csv:/opt/local/hpds/allConcepts.csv \
-v /usr/local/docker-config/hpds_csv/allConcepts_newPatNums.csv:/opt/local/hpds/allConcepts_newPatNums.csv \
-v /usr/local/docker-config/hpds_csv/allConcepts_newPaths.csv:/opt/local/hpds/allConcepts_newPaths.csv \
-v /usr/local/docker-config/hpds_csv/phenotypeInputs.txt:/opt/local/hpds/phenotypeInputs.txt \
-e HEAPSIZE=4096 -e LOADER_NAME=SequentialLoader hms-dbmi/pic-sure-hpds-etl:LATEST $PROFILING_OPTS &amp;&amp; \
mv /usr/local/docker-config/hpds /usr/local/docker-config/hpds_bak &amp;&amp; \
mv /usr/local/docker-config/hpds_temp /usr/local/docker-config/hpds
</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>
